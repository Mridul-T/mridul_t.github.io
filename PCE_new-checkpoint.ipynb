{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "from scipy.integrate import quad ## FUNCTIONS TO IMPLEMENT GAUSS-QUADRATURE\n",
    "# from scipy.integrate import quad_vec ## FUNCTIONS TO IMPLEMENT GAUSS-QUADRATURE\n",
    "from scipy.special import hermite,legendre\n",
    "from scipy.linalg import eigh\n",
    "import time\n",
    "np.random.seed(20)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will set the default to float32 or float64 but not float16\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_device = torch.cuda.current_device()\n",
    "# torch.cuda.get_device_properties(current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default tensor type to use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    torch.set_default_tensor_type(torch.FloatTensor)\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the orthonormal probabilistic Hermite polynomial\n",
    "def orthonormal_prob_hermite(n):\n",
    "    return lambda x: hermite(n)(x/np.sqrt(2.0)) / np.sqrt((2.0)**n * np.math.factorial(n))\n",
    "\n",
    "# Define the orthonormal probabilistic Legendre polynomial\n",
    "def orthonormal_legendre(n):\n",
    "    return lambda x: legendre(n)(x) * np.sqrt(n+0.5)\n",
    "\n",
    "# Define the integrand for scalar product\n",
    "def scalar_int(i,j):\n",
    "    return lambda x:orthonormal_prob_hermite(i)(x) * orthonormal_prob_hermite(j)(x) * np.exp(-(x**2/2))/np.sqrt(2*np.pi)\n",
    "\n",
    "# Define the integrand for triple product\n",
    "def triple_int(i,j,k):\n",
    "    return lambda x:orthonormal_prob_hermite(i)(x) * orthonormal_prob_hermite(j)(x)* orthonormal_prob_hermite(k)(x) * np.exp(-(x**2/2))/np.sqrt(2*np.pi)\n",
    "\n",
    "# Integrate to verify orthonormality\n",
    "integral1, _ = quad(scalar_int(2,2), -np.inf, np.inf)\n",
    "integral2, _ = quad(scalar_int(2,3), -np.inf, np.inf)\n",
    "print(f\"The scalar product of the orthonormal probabilistic Hermite polynomials H_2(x) and H_2(x) is approximately {integral1}\")\n",
    "print(f\"The scalar product of the orthonormal probabilistic Hermite polynomials H_2(x) and H_3(x) is approximately {integral2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "con = 1\n",
    "particles_per_unit=50*k\n",
    "dx = con/particles_per_unit\n",
    "ratio=1.6\n",
    "h=ratio*dx\n",
    "c_ = 2 * h\n",
    "q=30\n",
    "max_ord=3\n",
    "n_samples=96 * 50\n",
    "\n",
    "J = particles_per_unit**2 #total number of particles\n",
    "rho = 1000*torch.ones(J)  ## for steel\n",
    "mass = rho * dx**2\n",
    "rho0=rho\n",
    "vis=0.05\n",
    "T = 0.15               # Total time of integration\n",
    "dt = 0.003          # Time step\n",
    "N = int(T/dt)\n",
    "N  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_combinations(q, max_ord,current_sum=0, current_combination=None, all_combinations=None):\n",
    "    if current_combination is None:\n",
    "        current_combination = []\n",
    "    if all_combinations is None:\n",
    "        all_combinations = []\n",
    "        \n",
    "    if len(current_combination) == q:\n",
    "        if current_sum < max_ord:\n",
    "            all_combinations.append(current_combination[:])\n",
    "        return all_combinations\n",
    "    \n",
    "    for i in range(max_ord - current_sum):\n",
    "        current_combination.append(i)\n",
    "        find_combinations(q, max_ord,current_sum + i, current_combination, all_combinations)\n",
    "        current_combination.pop()\n",
    "\n",
    "    return all_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=np.array(find_combinations(q,max_ord))\n",
    "P=index.shape[0]\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = torch.linspace(0, 1*con, particles_per_unit)\n",
    "y_values = torch.linspace(0, 1*con, particles_per_unit)\n",
    "# Create a meshgrid\n",
    "X, Y = torch.meshgrid(x_values, y_values)\n",
    "# print(X.shape)\n",
    "\n",
    "# Flatten the meshgrid arrays for 1D function application\n",
    "X_flat = X.flatten()\n",
    "Y_flat = Y.flatten()\n",
    "\n",
    "temp=tuple(zip(X_flat,Y_flat))\n",
    "temp=torch.tensor(temp)\n",
    "coords=torch.zeros(P,J,2)\n",
    "coords[0]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample(i):\n",
    "    np.random.seed(i)\n",
    "    L=4\n",
    "    a_ij = np.random.normal(0, 1, (2,2*L+1, 2*L+1))\n",
    "    b_ij = np.random.normal(0, 1, (2,2*L+1, 2*L+1))\n",
    "    c = np.random.uniform(-1, 1, 2)\n",
    "    \n",
    "    \n",
    "    # Define the w(x, y) function\n",
    "    def w(x, y,n=particles_per_unit):\n",
    "        result = torch.zeros(2,n,n).cpu()\n",
    "        m = torch.ones(2,n,n).cpu()\n",
    "        for i in range(-L, L+1):\n",
    "            for j in range(-L, L+1):\n",
    "                result[0] += (a_ij[0,i+L, j+L] * np.sin(2*np.pi*(i*x.cpu() + j*y.cpu())) + b_ij[0,i+L, j+L] * np.cos(2*np.pi*(i*x.cpu() + j*y.cpu())))\n",
    "                result[1] += (a_ij[1,i+L, j+L] * np.sin(2*np.pi*(i*x.cpu() + j*y.cpu())) + b_ij[1,i+L, j+L] * np.cos(2*np.pi*(i*x.cpu() + j*y.cpu()))) \n",
    "        m[0] = 10*(1-(np.exp((y.cpu())*(1-y.cpu())))) *(1-(np.exp((-x.cpu())*(1-x.cpu()))))\n",
    "        m[1] = 10*(1-(np.exp((y.cpu())*(1-y.cpu())))) *(1-(np.exp((-x.cpu())*(1-x.cpu()))))\n",
    "        return result,m\n",
    "\n",
    "\n",
    "    # Calculate w(x, y) over the grid\n",
    "    W,m = w(X, Y)\n",
    "    # print(W.shape)\n",
    "    # # Calculate u(x, y, t=0)\n",
    "    # temp = W\n",
    "    temp = 2 * W / torch.max(torch.abs(W)).cpu()\n",
    "    temp[0] = (temp[0] + c[0])*m[0]\n",
    "    temp[1] = (temp[1] + c[1])*m[1]\n",
    "    u0 = torch.zeros((2, J))\n",
    "    u0[0,:]=temp[0,:,:].flatten()\n",
    "    u0[1,:]=temp[1,:,:].flatten()\n",
    "    return u0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_init=torch.zeros((2,particles_per_unit**2,n_samples))\n",
    "# for i in range(n_samples):\n",
    "#     print(f\"Starting the {i}th iteration\")\n",
    "#     u_init[:,:,i]=create_sample(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('u_init.pkl', 'rb') as file:\n",
    "    u_init = torch.tensor(pickle.load(file), dtype=torch.float32).permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_stacked = u_init.transpose(1, 2).reshape(2, 2000, 2500)\n",
    "u_stacked = u_init\n",
    "\n",
    "# Compute the covariance matrix for each component (x and y)\n",
    "cov_matrices = []\n",
    "for component in range(2):\n",
    "    u_component = u_stacked[component]  # Select either x or y component\n",
    "    # Subtract the mean along the sample dimension (axis=1)\n",
    "    u_mean = torch.mean(u_component, dim=(1), keepdim=True)\n",
    "    u_centered = u_component - u_mean\n",
    "    # Compute covariance matrix\n",
    "    covariance_matrix = torch.matmul(u_centered, u_centered.transpose(1, 0)) / (u_component.shape[1] - 1)\n",
    "    cov_matrices.append(covariance_matrix)\n",
    "\n",
    "# cov_matrices now contains the covariance matrix for each component\n",
    "cov_x = cov_matrices[0]  # Covariance matrix for x component\n",
    "cov_y = cov_matrices[1]  # Covariance matrix for y component\n",
    "\n",
    "# If you want the combined covariance matrix, you can stack them together\n",
    "cov_combined = torch.stack(cov_matrices, dim=0)\n",
    "\n",
    "print(\"Covariance matrix for x component:\\n\", cov_x.shape)\n",
    "print(\"Covariance matrix for y component:\\n\", cov_y.shape)\n",
    "print(\"Combined covariance matrix:\\n\", cov_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the eigenvalues_x and eigenvectors_x of the covariance matrix\n",
    "eigenvalues_x, eigenvectors_x = eigh(cov_x.cpu())\n",
    "\n",
    "# Sort the eigenvalues_x and eigenvectors_x in descending order\n",
    "idx = eigenvalues_x.argsort()[::-1]\n",
    "eigenvalues_x = torch.tensor(eigenvalues_x[idx])\n",
    "eigenvectors_x = torch.tensor(eigenvectors_x[:, idx])\n",
    "eigenvalues_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the eigenvalues_y and eigenvectors_y of the covariance matrix\n",
    "eigenvalues_y, eigenvectors_y = eigh(cov_y.cpu())\n",
    "\n",
    "# Sort the eigenvalues_y and eigenvectors_y in descending order\n",
    "idx = eigenvalues_y.argsort()[::-1]\n",
    "eigenvalues_y = torch.tensor(eigenvalues_y[idx])\n",
    "eigenvectors_y = torch.tensor(eigenvectors_y[:, idx])\n",
    "eigenvalues_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues_x[356:          366]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0_mean=u_init.mean(dim=(2))\n",
    "u0_std=u_init.std(dim=(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_plot=u0_mean[1,:].cpu().reshape((int(np.sqrt(J)), int(np.sqrt(J))))\n",
    "heatmap=plt.imshow(u_plot, aspect='auto', cmap='jet')\n",
    "plt.xlabel('Spatial dimension (y)')\n",
    "plt.ylabel('Spatial dimension (x)')\n",
    "plt.title(f'Inital Conditions for q={q}', fontweight='bold')\n",
    "cbar = plt.colorbar(heatmap)\n",
    "# Add colorbar with legend\n",
    "# cbar = plt.colorbar(heatmap)\n",
    "cbar.set_label('Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_plot=u0_std[1,:].cpu().reshape((int(np.sqrt(J)), int(np.sqrt(J))))\n",
    "heatmap=plt.imshow(u_plot, aspect='auto', cmap='jet')\n",
    "plt.xlabel('Spatial dimension (y)')\n",
    "plt.ylabel('Spatial dimension (x)')\n",
    "plt.title(f'Inital Conditions for q={q} by MCS', fontweight='bold')\n",
    "cbar = plt.colorbar(heatmap)\n",
    "# Add colorbar with legend\n",
    "# cbar = plt.colorbar(heatmap)\n",
    "cbar.set_label('Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "# q=100\n",
    "for i in range(q):\n",
    "    t+=eigenvalues_y[i]*(eigenvectors_y[:,i]**2)\n",
    "t=torch.sqrt(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_plot=t.cpu().reshape((int(np.sqrt(J)), int(np.sqrt(J))))\n",
    "heatmap=plt.imshow(u_plot, aspect='auto', cmap='jet')\n",
    "plt.xlabel('Spatial dimension (y)')\n",
    "plt.ylabel('Spatial dimension (x)')\n",
    "plt.title(f'Inital Conditions for q={q}', fontweight='bold')\n",
    "cbar = plt.colorbar(heatmap)\n",
    "# Add colorbar with legend\n",
    "# cbar = plt.colorbar(heatmap)\n",
    "cbar.set_label('Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_u(wx,wy):\n",
    "    val=u0_mean\n",
    "    \n",
    "    for i in range(q):\n",
    "        val[0]+=torch.sqrt(eigenvalues_x[i])*(eigenvectors_x[:,i])*wx[i]\n",
    "        val[1]+=torch.sqrt(eigenvalues_y[i])*(eigenvectors_y[:,i])*wy[i]\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=torch.zeros(size=(2,P,J))\n",
    "values[:,0,:]=u0_mean\n",
    "for i in range(1,P):\n",
    "    print(i)\n",
    "    val=torch.zeros_like(u0_mean)\n",
    "    for j in range(q):\n",
    "        k = index[i][j]\n",
    "        if (k==1 and np.sum(index[i])==1) or k==2:\n",
    "            temp,_=quad(lambda x: orthonormal_prob_hermite(k)(x) * x * np.exp(-(x**2/2))/np.sqrt(2*np.pi), -np.inf, np.inf)\n",
    "            if(abs(temp)<1e-5):\n",
    "                temp=0\n",
    "            # print(f\"{k} for nananaaaa naaa{temp}\")\n",
    "            val[0]+=torch.sqrt(eigenvalues_x[j])*eigenvectors_x[:,j]*temp\n",
    "            val[1]+=torch.sqrt(eigenvalues_y[j])*eigenvectors_y[:,j]*temp\n",
    "            break\n",
    "    values[:,i,:]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut = torch.zeros((2, P, J, N+1))\n",
    "ut[:,:,:,0]=torch.tensor(values)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(torch.abs(u_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del u_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_b=torch.zeros((max_ord,max_ord),device='cpu')\n",
    "for i in range(max_ord):\n",
    "    for j in range(max_ord):\n",
    "        pre_b[i,j],_=quad(lambda x: orthonormal_prob_hermite(i)(x)*orthonormal_prob_hermite(j)(x)* np.exp(-(x**2/2))/np.sqrt(2*np.pi), -np.inf, np.inf)\n",
    "        if(abs(pre_b[i,j])<1e-10):\n",
    "            pre_b[i,j]=0\n",
    "pre_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_c=torch.zeros((max_ord,max_ord,max_ord),device='cpu')\n",
    "for i in range(max_ord):\n",
    "    for j in range(max_ord):\n",
    "        for k in range(max_ord):\n",
    "            pre_c[i,j,k],_=quad(lambda x: orthonormal_prob_hermite(i)(x)*orthonormal_prob_hermite(j)(x)* orthonormal_prob_hermite(k)(x) *np.exp(-(x**2/2))/np.sqrt(2*np.pi), -np.inf, np.inf)\n",
    "            if(abs(pre_c[i,j,k])<1e-10):\n",
    "                pre_c[i,j,k]=0\n",
    "pre_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_b(i, pre_b, index):\n",
    "    print(f\"Starting {i}th iteration\")\n",
    "    b = torch.zeros(size=(P,),device='cpu')\n",
    "    for j in range(P):\n",
    "        b[j]=1\n",
    "        for k in range(q):\n",
    "            b[j]*=pre_b[index[i][k],index[j][k]]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=torch.tensor(index,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_c(i, pre_c, index):\n",
    "    print(f\"Starting {i}th iteration\")\n",
    "    P, q = index.shape\n",
    "#     index=torch.tensor(index)\n",
    "    # Initialize the output tensor c with ones\n",
    "    c = torch.ones((P, P), dtype=pre_c.dtype, device=pre_c.device)\n",
    "    \n",
    "    # Iterate over the range Q and perform element-wise multiplication for all combinations\n",
    "    for l in range(q):\n",
    "        idx_i = index[i, l]\n",
    "        idx_j = index[:, l].unsqueeze(1).expand(P, P)\n",
    "        idx_k = index[:, l].unsqueeze(0).expand(P, P)\n",
    "        c *= pre_c[idx_i, idx_j, idx_k]\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores=multiprocessing.cpu_count()\n",
    "num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "b = Parallel(n_jobs=num_cores)(delayed(cal_b)(i, pre_b, index) for i in range(P))\n",
    "c = Parallel(n_jobs=num_cores)(delayed(cal_c)(i, pre_c, index) for i in range(P))\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total time taken {(end-start)/60} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=torch.stack(b,dim=0)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=torch.stack(c,dim=0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nlist(coords,side_length=float(con)):\n",
    "    # Compute pairwise distance\n",
    "    # Shifts\n",
    "    eps = 0.1*h\n",
    "    shifts = [\n",
    "        (0, 0)        # Original coordinates\n",
    "        # (side_length, 0),  # Shift right\n",
    "        # (-side_length, 0), # Shift left\n",
    "        # (0, side_length),  # Shift up\n",
    "        # (0, -side_length), # Shift down \n",
    "        # (side_length + eps, -side_length - eps),  # Shift right - down\n",
    "        # (-side_length - eps, side_length + eps), # Shift left - up\n",
    "        # (side_length + eps, side_length + eps),  # Shift right - up\n",
    "        # (-side_length - eps, -side_length - eps)  # Shift left - down \n",
    "    ]\n",
    "    n_particles=coords.size()[0]\n",
    "    # Expand the coordinates\n",
    "    \n",
    "    all_coords = []\n",
    "    for shift in shifts:\n",
    "        shifted_coords = coords + torch.tensor(shift,dtype=coords.dtype)\n",
    "        all_coords.append(shifted_coords)\n",
    "\n",
    "    \n",
    "    all_coords = torch.cat(all_coords, dim=0)\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    dX = all_coords[:, 0][:, None] - coords[:, 0][None, :]\n",
    "    dY = all_coords[:, 1][:, None] - coords[:, 1][None, :]\n",
    "    # print(dX.shape)\n",
    "    # half_domain = side_length / 2\n",
    "    # dX = (dX + half_domain) % side_length - half_domain\n",
    "    # dY = (dY + half_domain) % side_length - half_domain\n",
    "    \n",
    "    distances = torch.sqrt(dX**2 + dY**2)\n",
    "\n",
    "    # Create the neighbor list using a mask for distances < c and excluding self-distances\n",
    "    neighbor_mask = (distances <= c_) & (distances > 0)\n",
    "    # print(neighbor_mask.shape)\n",
    "    # Compute the neighbor list\n",
    "    n_list = [[torch.nonzero(neighbor_mask[i]).squeeze() % n_particles,(dX[i][neighbor_mask[i]]),(dY[i][neighbor_mask[i]])] for i in range(J)]\n",
    "    \n",
    "    return n_list\n",
    "\n",
    "n_list=compute_nlist(coords[0])\n",
    "len(n_list[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_CubicSpline(x, y, h, domain_size=1):\n",
    "    alpha = 15/(7*np.pi*h**2)\n",
    "\n",
    "\n",
    "    r = torch.sqrt(x**2 + y**2)\n",
    "    q = r / h\n",
    "    mask1 = q <= 1\n",
    "    mask2 = (q > 1) & (q <= 2)\n",
    "    dz_dx = torch.zeros_like(q)\n",
    "    dz_dy = torch.zeros_like(q)\n",
    "\n",
    "    dz_dx[mask1] = alpha * (-2*q[mask1] + 3/2*q[mask1]**2) * x[mask1] / (r[mask1] * h)\n",
    "    dz_dy[mask1] = alpha * (-2*q[mask1] + 3/2*q[mask1]**2) * y[mask1] / (r[mask1] * h)\n",
    "    dz_dx[mask2] = alpha * (-1/2*(2-q[mask2])**2) * x[mask2] / (r[mask2] * h)\n",
    "    dz_dy[mask2] = alpha * (-1/2*(2-q[mask2])**2) * y[mask2] / (r[mask2] * h)\n",
    "    \n",
    "    return dz_dx, dz_dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_A(x, y, h, m_j, rho_j, epsilon=1e-8):\n",
    "    alpha = 15 / (7 * np.pi * h ** 2)\n",
    "    r = torch.sqrt(x**2 + y**2)\n",
    "    q = r / h\n",
    "    mask1 = q <= 1\n",
    "    mask2 = (q > 1) & (q <= 2)\n",
    "    \n",
    "    W_xx = torch.zeros_like(q)\n",
    "    W_yy = torch.zeros_like(q)\n",
    "    \n",
    "    W_xx[mask1] = alpha * (-2 * q[mask1] + 3/2 * q[mask1]**2) * (x[mask1]) / (r[mask1] * h)\n",
    "    W_yy[mask1] = alpha * (-2 * q[mask1] + 3/2 * q[mask1]**2) * (y[mask1]) / (r[mask1] * h)\n",
    "    W_xx[mask2] = alpha * (-1/2 * (2 - q[mask2])**2) * (x[mask2]) / (r[mask2] * h)\n",
    "    W_yy[mask2] = alpha * (-1/2 * (2 - q[mask2])**2) * (y[mask2]) / (r[mask2] * h)\n",
    "    \n",
    "    A_xx = -torch.sum(m_j * x / rho_j * W_xx)\n",
    "    A_xy = -torch.sum(m_j * x / rho_j * W_yy)\n",
    "    A_yx = -torch.sum(m_j * y / rho_j * W_xx)\n",
    "    A_yy = -torch.sum(m_j * y / rho_j * W_yy)\n",
    "    \n",
    "    A_inv = torch.linalg.inv(torch.tensor([[A_xx, A_xy], [A_yx, A_yy]]))\n",
    "    return A_inv\n",
    "\n",
    "def d_CubicSpline_corrected(x, y, h, m_j, rho_j):\n",
    "    # Compute the gradient of the kernel\n",
    "    dz_dx, dz_dy = d_CubicSpline(x, y, h)\n",
    "    \n",
    "    # Compute the correction matrix A_inv\n",
    "    B = compute_A(x, y, h, m_j, rho_j)\n",
    "    \n",
    "    # Apply the gradient correction\n",
    "    dz_dx_corrected = B[0, 0] * dz_dx + B[0, 1] * dz_dy\n",
    "    dz_dy_corrected = B[1, 0] * dz_dx + B[1, 1] * dz_dy\n",
    "    \n",
    "    return dz_dx_corrected, dz_dy_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SPH(c,h,comp,n_list=n_list):\n",
    "    cd=torch.zeros(size=(2,P,c.shape[1]))\n",
    "    for i,data in enumerate(n_list):\n",
    "        neighbors = data[0]\n",
    "        c_i = c[:,i][:,np.newaxis]  # Broadcasting to create the necessary shape\n",
    "        c_i = torch.tensor(np.repeat(c_i.cpu(), len(neighbors), axis=1),device=cd.device)\n",
    "        c_j = c[:,neighbors]\n",
    "        rho_neighbors = rho[neighbors]\n",
    "        mass_neighbors = mass[neighbors]\n",
    "        \n",
    "        c_diff = c_i - c_j\n",
    "        # dx,dy=d_CubicSpline_corrected(data[1],data[2], h, mass_neighbors, rho_neighbors)\n",
    "        dx,dy=d_CubicSpline(data[1],data[2],h)\n",
    "        cd[0,:,i] = torch.einsum(\"N,PN->P\", mass_neighbors / rho_neighbors * dx, c_diff)\n",
    "        cd[1,:,i] = torch.einsum(\"N,PN->P\", mass_neighbors / rho_neighbors * dy, c_diff)\n",
    "    return cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SPH_d(c,h,n_list=n_list):\n",
    "    cd=torch.zeros_like(c)\n",
    "    for i,data in enumerate(n_list):\n",
    "        neighbors = data[0]\n",
    "        c_i = c[:,:,i][:,:,np.newaxis]  # Broadcasting to create the necessary shape\n",
    "        c_i = torch.tensor(np.repeat(c_i.cpu(), len(neighbors), axis=2),device=cd.device)\n",
    "        c_j = c[:,:,neighbors]\n",
    "        rho_neighbors = rho[neighbors]\n",
    "        mass_neighbors = mass[neighbors]\n",
    "        c_diff = (c_i - c_j)\n",
    "        # dx,dy=d_CubicSpline_corrected(data[1],data[2], h, mass_neighbors, rho_neighbors)\n",
    "        dx,dy=d_CubicSpline(data[1],data[2],h)\n",
    "        cd[0,:,i] = torch.einsum(\"N,PN->P\",mass_neighbors / rho_neighbors * dx, c_diff[0,:,:])\n",
    "        cd[1,:,i] = torch.einsum(\"N,PN->P\",mass_neighbors / rho_neighbors * dy, c_diff[1,:,:])\n",
    "    return cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xSPH(c,h,n_list=n_list):\n",
    "    cd=torch.zeros_like(c)\n",
    "    for i,data in enumerate(n_list):\n",
    "        neighbors = data[0]\n",
    "        c_i = c[:,:,i][:,:,np.newaxis]  # Broadcasting to create the necessary shape\n",
    "        c_i = torch.tensor(np.repeat(c_i.cpu(), len(neighbors), axis=2),device=cd.device)\n",
    "        c_j = c[:,:,neighbors]\n",
    "        rho_neighbors = rho[neighbors]\n",
    "        mass_neighbors = mass[neighbors]\n",
    "        c_diff = (c_j - c_i)\n",
    "        # dx,dy=d_CubicSpline_corrected(data[1],data[2], h,mass_neighbors,rho_neighbors)\n",
    "        dx,dy=d_CubicSpline(data[1],data[2],h)\n",
    "        # cd[0,:,i] = torch.sum(mass_neighbors / rho_neighbors * c_diff * dx)\n",
    "        cd[0,:,i] = 0.5*torch.einsum(\"N,PN->P\",mass_neighbors / rho_neighbors * dx, c_diff[0,:,:])\n",
    "        cd[1,:,i] = 0.5*torch.einsum(\"N,PN->P\",mass_neighbors / rho_neighbors * dy, c_diff[1,:,:])\n",
    "        # cd[0,0,i] += torch.sum(mass_neighbors / rho_neighbors * (pi_ij) * dx)\n",
    "        # cd[1,0,i] += torch.sum(mass_neighbors / rho_neighbors * (pi_ij) * dy)\n",
    "    return cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to detect and correct outliers based on the median\n",
    "def median_outlier_correction(ut, neighborlist):\n",
    "    # Iterate over all particles\n",
    "    for j in range(ut.shape[2]):\n",
    "        neighbors = neighborlist[j][0]\n",
    "        if len(neighbors) > 0:  # Check if the particle has neighbors\n",
    "            # Compute the median velocity from the neighbors\n",
    "            median_velocity_x = torch.median(ut[0, :, neighbors], dim=1).values\n",
    "            median_velocity_y = torch.median(ut[1, :, neighbors], dim=1).values\n",
    "            # Update the velocity of the current particle to the median velocity of neighbors\n",
    "            ut[0, :, j] = median_velocity_x\n",
    "            ut[1, :, j] = median_velocity_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates=torch.zeros((P,J,2,N+1))\n",
    "coordinates[:,:,:,0]=coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords[1,:51,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mask = torch.logical_or(coords[0,:,0] == 0, coords[0,:,0] == 1)\n",
    "y_mask = torch.logical_or(coords[0,:,1] == 0, coords[0,:,1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mask[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1, N+1):\n",
    "    # Predictor step\n",
    "    n_list = compute_nlist(coords[0])\n",
    "    u = ut[:, :, :, n - 1]\n",
    "    \n",
    "    # Derivatives for predictor\n",
    "    ux_d = SPH(u[0], h, 0)\n",
    "    uy_d = SPH(u[1], h, 1)\n",
    "    ux_dd = SPH_d(ux_d, h)\n",
    "    uy_dd = SPH_d(uy_d, h)\n",
    "    \n",
    "    # Compute right-hand side for predictor\n",
    "    rhsx = torch.einsum('ji,ki,jlk->li', u[0], ux_d[0], c) + torch.einsum('ji,ki,jlk->li', u[1], ux_d[1], c) \\\n",
    "           - vis * (ux_dd[0] + ux_dd[1])\n",
    "    rhsy = torch.einsum('ji,ki,jlk->li', u[0], uy_d[0], c) + torch.einsum('ji,ki,jlk->li', u[1], uy_d[1], c) \\\n",
    "           - vis * (uy_dd[0] + uy_dd[1])\n",
    "    \n",
    "    # Predict new values of u (predictor estimate)\n",
    "    # u_pred_x = u[0] - rhsx * dt\n",
    "    # u_pred_y = u[1] - rhsy * dt\n",
    "    ut[0, :, :, n] = u[0] - rhsx * dt\n",
    "    ut[1, :, :, n] = u[1] - rhsy * dt\n",
    "    \n",
    "    # Corrector step\n",
    "    # Update the derivatives and right-hand side using the predictor values\n",
    "    # ux_d_pred = SPH(u_pred_x, h, 0)\n",
    "    # uy_d_pred = SPH(u_pred_y, h, 1)\n",
    "    # ux_dd_pred = SPH_d(ux_d_pred, h)\n",
    "    # uy_dd_pred = SPH_d(uy_d_pred, h)\n",
    "    \n",
    "    # # Compute right-hand side for corrector\n",
    "    # rhsx_pred = torch.einsum('ji,ki,jlk->li', u_pred_x, ux_d_pred[0], c) + torch.einsum('ji,ki,jlk->li', u_pred_y, ux_d_pred[1], c) \\\n",
    "    #             - vis * (ux_dd_pred[0] + ux_dd_pred[1])\n",
    "    # rhsy_pred = torch.einsum('ji,ki,jlk->li', u_pred_x, uy_d_pred[0], c) + torch.einsum('ji,ki,jlk->li', u_pred_y, uy_d_pred[1], c) \\\n",
    "    #             - vis * (uy_dd_pred[0] + uy_dd_pred[1])\n",
    "    \n",
    "    # Correct the time integration with the average of predictor and corrector rhs\n",
    "    # ut[0, :, :, n] = u[0] - 0.5 * (rhsx + rhsx_pred) * dt\n",
    "    # ut[1, :, :, n] = u[1] - 0.5 * (rhsy + rhsy_pred) * dt\n",
    "    \n",
    "    # Boundary conditions\n",
    "    ut[0, :, torch.logical_or(x_mask,y_mask), n] = 0\n",
    "    ut[1, :, torch.logical_or(x_mask,y_mask), n] = 0\n",
    "\n",
    "    coords = coords +  (ut[:,:,:,n]).transpose(0,2).transpose(0,1) * dt\n",
    "    coordinates[:,:,:,n]=coords\n",
    "    print(f\"Completed the {n}^th timestep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('results_pce_new.pkl', 'wb') as file:\n",
    "    pickle.dump(ut.numpy(), file)\n",
    "with open('coords_pce_new.pkl', 'wb') as file:\n",
    "    pickle.dump(coordinates.numpy(), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total time taken {(t2-t1)/60} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
